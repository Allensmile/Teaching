{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skimage\n",
    "\n",
    "Python possesses a powerful library for image analysis: [Skimage](http://scikit-image.org/). An image is represented as a Numpy array (2D for black and white and 3D for color images). Sklearn implements algorithms for all common manipulations of images: filtering, edge detection, transformations, texture detection...\n",
    "\n",
    "We will give two small examples (mainly to show of the `interact` in IPython notebook).\n",
    "\n",
    "More examples can be found on the main page.\n",
    "\n",
    "## 1. Finding blobs\n",
    "\n",
    "A basis form of image analysis is blob detection: finding regions in the image with different color, intensity... compared to the surroundings. This is often done to, for example, count cells in a microscopy image. Here we will use this to count galaxies in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage import data  # Skimage contains a set of example images\n",
    "from skimage.feature import blob_log\n",
    "from skimage.color import rgb2gray\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = data.hubble_deep_field()[:600,:600]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image, interpolation='nearest')  # show image, just treat is as a matrix\n",
    "image_gray = rgb2gray(image)  # set to grayscale for blob detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Laplacian of Gaussian (Log) method to find the galaxies. This methods has threshold parameter that has to be tuned: the higher the beter the specificity but the lower the sensitivity.\n",
    "\n",
    "First we will create a subroutine to perform the blob detection for a given threshold values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect_blobs(threshold):\n",
    "    blobs_log = blob_log(image_gray, max_sigma=30, num_sigma=10, threshold=threshold)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.set_title('Number of blobs')\n",
    "    ax.imshow(image)\n",
    "    for blob in blobs_log:\n",
    "        y, x, r = blob\n",
    "        c = plt.Circle((x, y), r, color='lime', linewidth=2, fill=False)\n",
    "        ax.add_patch(c)\n",
    "    print(\"Detected %i galaxies with a threshold of %s\" %(len(blobs_log), threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used to create a simple widget with a slider using the interact modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import interact\n",
    "\n",
    "interact(detect_blobs, threshold=(0.01, 0.5, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Segementation using clustering\n",
    "\n",
    "Another common task in image analysis is segmentation, i.e. dividing the image into regions with similar propperties. This can be done using $k$-means clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.data import coffee\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import numpy as np\n",
    "coffee = coffee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_shape = coffee.shape\n",
    "print(image_shape)\n",
    "plt.imshow(coffee)\n",
    "coffee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our image is represented by a $400\\times600\\times3$ array. We can squeeze the image to a datamatrix where the observations (i.e. rows) correspond to the 240000 pixels and the three columns are the RGB values. Subsequently we use $k$-means clustering to find regions with similar color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=10)\n",
    "%time cluster_kmeans = kmeans_clustering.fit_predict(coffee.reshape(-1, 3))\n",
    "segm_image_km = kmeans_clustering.cluster_centers_[cluster_kmeans].reshape(image_shape)/255\n",
    "plt.imshow(segm_image_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! But segmentation takes quite long, as $k$-means is applied on a large dataset (240000 pixels!). Sklearn is equipped to deal with large datasets and often there exist algorithms which can be run on multiple processors. For $k$-means clustering there is an example which works by dividing the data into minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans_clustering_minbatch = MiniBatchKMeans(n_clusters=10, batch_size=5000)\n",
    "%time cluster_kmeans_minibatch = kmeans_clustering_minbatch.fit_predict(coffee.reshape(-1, 3))\n",
    "segm_image_kmmb = kmeans_clustering_minbatch.cluster_centers_[cluster_kmeans].reshape(image_shape)/255\n",
    "plt.imshow(segm_image_kmmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the running time has decreased, but our outcome is rather crappy... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def mini_batch_km_segmentation(n_clusters=(3, 50, 1), batch_size=(100, 100000, 1000)):\n",
    "    kmeans_clustering_minbatch = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size)\n",
    "    %time cluster_kmeans_minibatch = kmeans_clustering_minbatch.fit_predict(coffee.reshape(-1, 3))\n",
    "    segm_image_kmmb = kmeans_clustering_minbatch.cluster_centers_[cluster_kmeans].reshape(image_shape)/255\n",
    "    plt.imshow(segm_image_kmmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biopython\n",
    "[Biopython](http://biopython.org/wiki/Main_Page) contains everything you need for analysing bioinformatics data:\n",
    "- parsing text-based bioinformatics files\n",
    "- accessing the most important databases (Uniprot, Genbank, Kegg...)\n",
    "- studying 3D protein structures\n",
    "- phylogenetics\n",
    "- ...\n",
    "\n",
    "Two small examples to get you started.\n",
    "\n",
    "## 1. Working with sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "for item in SeqIO.FastaIO.FastaIterator(open('data/sweet_taste_receptor.txt', 'r')):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence = item.seq\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence.alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what we can do with one sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence.reverse_complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translated = sequence.translate()\n",
    "translated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Calculate isoelectric point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protein_analyser = ProteinAnalysis(str(translated))\n",
    "print(protein_analyser.isoelectric_point())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Reading multiple sequence alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alignment = AlignIO.read(\"data/muscle_cons_refs.txt\", \"clustal\")\n",
    "alignment.sort()\n",
    "print(alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate a quick concensus sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "align_summary = AlignInfo.SummaryInfo(alignment)\n",
    "print(align_summary.dumb_consensus(threshold=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AA_freq_pos = []\n",
    "n = alignment.get_alignment_length()\n",
    "\n",
    "for i in range(n):\n",
    "    if alignment[0,i] is not '-':\n",
    "        AA_freq_pos.append(Counter(alignment[1:,i]))\n",
    "\n",
    "AA_table = pd.DataFrame(AA_freq_pos).T\n",
    "AA_table = AA_table.fillna(0)  # remove NA\n",
    "AA_table = AA_table[1:]  # remove empty char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AA_table /= AA_table.sum()\n",
    "AA_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AA_table.T.plot(figsize=(15, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
